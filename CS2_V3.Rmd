---
title: "CS2"
author: "Melissa Luzardo"
date: "April 2, 2018"
output: 
 html_document:
   keep_md: true
---

## Source Documents

``` {r echo=TRUE, comment=NA, results='asis'}

#load requeried library
library("readxl")
require(RCurl)


## Saved the xlsx documents on GitHub, the code below process information from GitHub instead of our local computers.

download.file("https://raw.githubusercontent.com/cyberkoolman/msds.6306.case.study.2/master/CaseStudy2-data.xlsx", "data2.xlsx", mode="wb")

## Assigned file to object 

case_data <- data.frame(read_excel("data2.xlsx"))

```


## Making the raw data tidy data


```{r echo=TRUE, results='asis'}


#Remove redundandt info: EmployeeCount, EmployeeNumber, "Over18", "StandardHours"

df <- case_data[,-c(9,22,27)]

# First load required libraries.
library(purrr)
library(dplyr)
library(knitr)

# Convert characters to factors.
df %>% map_if(is.character, as.factor) %>% as_data_frame -> df

#Adjust factor levels
levels(df$BusinessTravel)<-c("Non-Travel","Travel_Rarely","Travel_Frequently")

#make all variable numeric
numdf<-data.frame(sapply(df,as.numeric))

```


##Find correlation coeffientes between parameters and Attrition


``` {r echo=TRUE,  results='asis'}


#Correlate variables
Attcor<-data.frame(cor(numdf))

#Create Attrition object for Attrition correlation coefficients 
Attrition<- data.frame(Attcor$Attrition)

#Name attrition rows
Attrition$Parameter<-row.names(Attcor)

#Rename titles Attrition
names(Attrition)<-c("Correlation", "Parameter")

#Sort Attrition
SortAtt <- Attrition[order(-Attrition$Correlation),]

#Display first 10
row.names(SortAtt)<-NULL
knitr::kable(head(SortAtt,10))

```

## Generate graphics for visualization of coeffiecients and correlations

```{r echo=TRUE,  results='asis'}

# Load library to visualize correlations
library(corrplot)

#Full graphic
par(cex=.5)
corrplot(as.matrix(Attcor), method="color", 
         type="upper", 
         addCoef.col = "black",
         tl.col="black", tl.srt=45,
         sig.level = 0.05, insig = "blank", 
         diag=FALSE)

#Graphic with highest 10
par(cex=.8)
SA10<-c(head(SortAtt$Parameter,10))
corrplot(as.matrix(Attcor[SA10,SA10]), method="pie", 
         type="upper", 
         addCoef.col = "black",
         tl.col="black", tl.srt=45,
         sig.level = 0.05, insig = "blank", 
         diag=FALSE)

#Closer look
par(mfrow=c(3,3), las=2)
plot(Attrition~OverTime, data=df)
plot(Attrition~MaritalStatus, data=df)
plot(Attrition~DistanceFromHome, data=df)
plot(Attrition~JobRole, data=df)
plot(Attrition~Department, data=df)
plot(Attrition~NumCompaniesWorked, data=df)
plot(Attrition~Gender, data=df)
plot(Attrition~EducationField, data=df)
plot(Attrition~MonthlyRate, data=df)

```

##Check with absolute values to look for highly correlated parameters with Attrition. And verify with graphics.
```{r echo=TRUE, comment=NA, results='asis'}
##Calculate absolute value coefficients
Attrition$AbsAtt <- (Attrition$Correlation^2)^(1/2)
SortAbstAtt<- Attrition[order(-Attrition$AbsAtt),]

#Display first 10 Absolute Correlated Parameters
row.names(SortAbstAtt)<-NULL
knitr::kable(head(SortAbstAtt,10))

#Graphic with highest 10
par(cex=.8)
SAA10<-c(head(SortAbstAtt$Parameter,10))
corrplot(as.matrix(Attcor[SAA10,SAA10]), method="pie", 
         type="upper", 
         addCoef.col = "black",
         tl.col="black", tl.srt=45,
         sig.level = 0.05, insig = "blank", 
         diag=FALSE)
##Generate graphics
par(mfrow=c(3,3), las=2)
plot(Attrition~OverTime, data=df)
plot(Attrition~TotalWorkingYears, data=df)
plot(Attrition~JobRole, data=df)
plot(Attrition~ MaritalStatus, data=df)
plot(Attrition~YearsInCurrentRole, data=df)
plot(Attrition~MonthlyIncome, data=df)
plot(Attrition~Age, data=df)
plot(Attrition~YearsWithCurrManager, data=df)
plot(Attrition~StockOptionLevel, data=df)
```

## Attemptinc logistic model

```{r echo=TRUE, comment=NA, results='asis'}

#Converting numeric variables as factors
LM <- df
LM$Education <- as.factor(LM$Education)
LM$EnvironmentSatisfaction <- as.factor(LM$EnvironmentSatisfaction)
LM$JobInvolvement <- as.factor(LM$JobInvolvement)
LM$JobSatisfaction <- as.factor(LM$JobSatisfaction)
LM$PerformanceRating <- as.factor(LM$PerformanceRating)
LM$RelationshipSatisfaction <- as.factor(LM$RelationshipSatisfaction)
LM$WorkLifeBalance <- as.factor(LM$WorkLifeBalance)

## Creating a Training and Testing data set from sampling
smp<-floor(0.8*nrow(LM))
set.seed(1234)
ind <- sample(seq_len(nrow(LM)),size=smp)
train <- LM[ind,]
test <- LM[-ind,]

#Logistic Regression
model <- glm(Attrition ~ ., family = binomial(link = 'logit'), data = train)
cat(model$aic)
summary(model)

#run anova
knitr::kable(anova(model, test = 'Chisq'))

## Model 2 - Creating a Logistic Regression Model by removing not statistically significant variables to reduce AIC value

model2 <- glm(Attrition ~ Age + BusinessTravel + DistanceFromHome + EnvironmentSatisfaction +   JobInvolvement + JobRole + JobSatisfaction + MaritalStatus + NumCompaniesWorked + OverTime +   RelationshipSatisfaction + TrainingTimesLastYear + WorkLifeBalance + YearsAtCompany + YearsInCurrentRole + YearsSinceLastPromotion + YearsWithCurrManager, family = binomial(link = 'logit'), data = train)

model2$aic

summary(model2)

#run anova
knitr::kable(anova(model2, test = 'Chisq'))

## Model 3 - Creating a Logistic Regression Model with hightes 3 statitstically significant parameters

model3 <- glm(Attrition ~ EnvironmentSatisfaction + MaritalStatus + OverTime , family = binomial(link = 'logit'), data = train)

model3$aic


## Prediction for the train data

predmodel2 <- round(predict(model2,train,type='response'),digits=0)
comparison2 <- data.frame(predmodel2,train$Attrition,train$EmployeeNumber)
names(comparison2)<- c("Predicted","Actual","EmployeeNumber")
knitr::kable(head(comparison2))

pred2 <- ifelse(predmodel2>0.5,2,1)

library(ROCR)
library(Metrics)
library(pROC)
pr <- prediction(pred2,train$Attrition)
perf <- performance(pr,measure = "tpr",x.measure = "fpr")
plot(perf)
auc(train$Attrition,pred2)

## Prediction for the test data

predmodel3 <- round(predict(model2,test,type='response'),digits=0)
comparison3 <- data.frame(predmodel3,test$Attrition,test$EmployeeNumber)
names(comparison3)<- c("Predicted","Actual","EmployeeNumber")
knitr::kable(head(comparison3))

pred3 <- ifelse(predmodel3>0.5,2,1)

pr3 <- prediction(pred3,test$Attrition)
perf3 <- performance(pr3,measure = "tpr",x.measure = "fpr")
plot(perf3)
auc(test$Attrition,pred3)

```

Ref.:
https://www.hackerearth.com/practice/machine-learning/machine-learning-algorithms/logistic-regression-analysis-r/tutorial/